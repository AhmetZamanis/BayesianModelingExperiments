{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from uplift_dgf import get_daily_visitors, get_daily_conversions, grid_configs\n",
    "from typing import List\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", \"Sampling:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot options\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set print options\n",
    "np.set_printoptions(suppress=True, precision=4, edgeitems = 7)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random generator\n",
    "random_seed = 1923\n",
    "rng = np.random.default_rng(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set true parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg. visitors per day & its noise, as Poisson distributions\n",
    "lam_visitors = 100\n",
    "lam_visitors_noise = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion rates\n",
    "conversion_control = 0.15\n",
    "conversion_experiment = 0.20\n",
    "true_relative_uplift = (conversion_experiment /conversion_control) - 1\n",
    "\n",
    "# Noise in conversion rates, as Beta distribution\n",
    "# Mean = alpha / (alpha + beta)\n",
    "conversion_noise_alpha = 3 \n",
    "conversion_noise_beta = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test conversion rate noise generation (will be randomly negated)\n",
    "sns.displot(\n",
    "    np.random.beta(conversion_noise_alpha, conversion_noise_beta, 1000)\n",
    ")\n",
    "_ = plt.title(f\"Conversion rate noise distribution, Beta({conversion_noise_alpha}, {conversion_noise_beta})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data & model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class VariantData:\n",
    "    visitors: int\n",
    "    conversions: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ConversionPrior:\n",
    "    alpha: float\n",
    "    beta: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversionRateModel:\n",
    "\n",
    "    def __init__(self, priors: List[ConversionPrior], data: List[VariantData], priors_label: str):\n",
    "\n",
    "        # Set the conversion rate priors\n",
    "        # 0: control, 1: experiment\n",
    "        self.prior_control = priors[0]\n",
    "        self.prior_experiment = priors[1]\n",
    "\n",
    "        # Get experiment data\n",
    "        # 0: control, 1: experiment\n",
    "        self.visitors = [variant.visitors for variant in data]\n",
    "        self.conversions = [variant.conversions for variant in data]\n",
    "\n",
    "        self.priors_label = priors_label\n",
    "        self.prior_predictive = None\n",
    "        self.posterior_predictive = None\n",
    "    \n",
    "    def _create_model(self):\n",
    "\n",
    "        # Define model\n",
    "        with pm.Model() as model:\n",
    "\n",
    "            # Conversion rate priors,\n",
    "            conversion_rate_control = pm.Beta(\n",
    "                \"conversion_rate_control\",\n",
    "                alpha = self.prior_control.alpha,\n",
    "                beta = self.prior_control.beta\n",
    "            )\n",
    "\n",
    "            conversion_rate_experiment = pm.Beta(\n",
    "                \"conversion_rate_experiment\",\n",
    "                alpha = self.prior_experiment.alpha,\n",
    "                beta = self.prior_experiment.beta\n",
    "            )\n",
    "\n",
    "            # Likelihoods\n",
    "            likelihood_control = pm.Binomial(\n",
    "                \"outcome_control\",\n",
    "                n = self.visitors[0],\n",
    "                p = conversion_rate_control,\n",
    "                observed = self.conversions[0]\n",
    "            )\n",
    "\n",
    "            likelihood_experiment = pm.Binomial(\n",
    "                \"outcome_experiment\",\n",
    "                n = self.visitors[1],\n",
    "                p = conversion_rate_experiment,\n",
    "                observed = self.conversions[1]\n",
    "            )\n",
    "\n",
    "            # Relative uplift\n",
    "            relative_uplift = pm.Deterministic(\n",
    "                \"relative_uplift\",\n",
    "                (conversion_rate_experiment / conversion_rate_control) - 1\n",
    "            )\n",
    "            \n",
    "        return model\n",
    "    \n",
    "    def get_prior_predictive(self, **kwargs):\n",
    "\n",
    "        # Sample prior predictive distribution\n",
    "        with self._create_model():\n",
    "            self.prior_predictive = pm.sample_prior_predictive(**kwargs)\n",
    "    \n",
    "    def get_posterior_predictive(self, **kwargs):\n",
    "\n",
    "        # Draw posterior samples\n",
    "        with self._create_model():\n",
    "            self.posterior_predictive = pm.sample(**kwargs)\n",
    "    \n",
    "    def plot_prior_predictive(self, kind = \"kde\", **kwargs):\n",
    "        \n",
    "        if self.prior_predictive == None:\n",
    "            self.get_prior_predictive(**kwargs)\n",
    "        \n",
    "        priors_label = self.priors_label\n",
    "\n",
    "        # Plot conversion rate priors\n",
    "        fig, ax = plt.subplots(2, sharex = True)\n",
    "\n",
    "        # Control\n",
    "        _ = az.plot_posterior(\n",
    "            self.prior_predictive.prior[\"conversion_rate_control\"],\n",
    "            kind = kind,\n",
    "            ax = ax[0]\n",
    "            )\n",
    "        _ = ax[0].axvline(conversion_control, color = \"red\")\n",
    "        _ = ax[0].annotate(str(round(conversion_control, 2)), (conversion_control, 0.2))\n",
    "        _ = ax[0].set_title(f\"Control conversion rate, {priors_label} prior predictive\")\n",
    "\n",
    "        # Experiment\n",
    "        _ = az.plot_posterior(\n",
    "            self.prior_predictive.prior[\"conversion_rate_experiment\"],\n",
    "            kind = kind,\n",
    "            ax = ax[1]\n",
    "            )\n",
    "        _ = ax[1].axvline(conversion_experiment, color = \"red\")\n",
    "        _ = ax[1].annotate(str(round(conversion_experiment, 2)), (conversion_experiment, 0.2))\n",
    "        _ = ax[1].set_title(f\"Experiment conversion rate, {priors_label} prior predictive\")\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        # Plot outcome prior\n",
    "        _ = az.plot_posterior(\n",
    "            self.prior_predictive.prior[\"relative_uplift\"],\n",
    "            kind = kind\n",
    "            )\n",
    "        _ = plt.axvline(true_relative_uplift, color = \"red\")\n",
    "        _ = plt.annotate(str(round(true_relative_uplift, 2)), (true_relative_uplift, 0.1))\n",
    "        _ = plt.title(f\"Relative uplift, {priors_label} prior predictive\")\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_posterior_predictive(self, kind = \"kde\", **kwargs):\n",
    "        \n",
    "        if self.posterior_predictive == None:\n",
    "            self.get_posterior_predictive(**kwargs)\n",
    "        \n",
    "        priors_label = self.priors_label\n",
    "\n",
    "        # Plot conversion rate posteriors\n",
    "        fig, ax = plt.subplots(2, sharex = True)\n",
    "\n",
    "        # Control\n",
    "        _ = az.plot_posterior(\n",
    "            self.posterior_predictive.posterior[\"conversion_rate_control\"],\n",
    "            kind = kind,\n",
    "            ax = ax[0]\n",
    "            )\n",
    "        _ = ax[0].axvline(conversion_control, color = \"red\")\n",
    "        _ = ax[0].annotate(str(round(conversion_control, 2)), (conversion_control, 0.2))\n",
    "        _ = ax[0].set_title(f\"Control conversion rate, {priors_label} posterior predictive\")\n",
    "\n",
    "        # Experiment\n",
    "        _ = az.plot_posterior(\n",
    "            self.posterior_predictive.posterior[\"conversion_rate_experiment\"],\n",
    "            kind = kind,\n",
    "            ax = ax[1]\n",
    "            )\n",
    "        _ = ax[1].axvline(conversion_experiment, color = \"red\")\n",
    "        _ = ax[1].annotate(str(round(conversion_experiment, 2)), (conversion_experiment, 0.2))\n",
    "        _ = ax[1].set_title(f\"Experiment conversion rate, {priors_label} posterior predictive\")\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        # Plot outcome posterior\n",
    "        _ = az.plot_posterior(\n",
    "            self.posterior_predictive.posterior[\"relative_uplift\"],\n",
    "            kind = kind\n",
    "            )\n",
    "        _ = plt.axvline(true_relative_uplift, color = \"red\")\n",
    "        _ = plt.annotate(str(round(true_relative_uplift, 2)), (true_relative_uplift, 0.1))\n",
    "        _ = plt.title(f\"Relative uplift, {priors_label} posterior predictive\")\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_variant_data(days: int, conversion_rates: List[float]):\n",
    "\n",
    "    # Assuming conversion_rates[0] is control\n",
    "    variant_data_list = []\n",
    "    \n",
    "    for rate in conversion_rates:\n",
    "        visitors = get_daily_visitors(days, lam_visitors, lam_visitors_noise, rng)\n",
    "        conversions = get_daily_conversions(visitors, rate, conversion_noise_alpha, conversion_noise_beta, rng)\n",
    "        variant_data = VariantData(sum(visitors), sum(conversions))\n",
    "        variant_data_list.append(variant_data)\n",
    "    \n",
    "    return variant_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preposterior analysis (EVSI estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Considered practically relevant effect sizes (relative uplift)\n",
    "# effect_sizes = [\n",
    "#     0.01,\n",
    "#     0.1,\n",
    "#     true_relative_uplift,  # 0.33\n",
    "#     0.5,\n",
    "#     0.8\n",
    "# ]\n",
    "\n",
    "# Considered number of days\n",
    "n_days = np.arange(1, 10, 2)\n",
    "\n",
    "# Considered priors\n",
    "weak_prior = [\n",
    "    ConversionPrior(1, 5),\n",
    "    ConversionPrior(1.5, 5.5)\n",
    "]\n",
    "\n",
    "medium_prior = [\n",
    "    ConversionPrior(15, 85),\n",
    "    ConversionPrior(25, 100)\n",
    "]\n",
    "\n",
    "strong_prior = [\n",
    "    ConversionPrior(60, 340),\n",
    "    ConversionPrior(100, 400)\n",
    "]\n",
    "\n",
    "priors = {\n",
    "    \"weak\": weak_prior, \n",
    "    \"medium\": medium_prior, \n",
    "    \"strong\": strong_prior\n",
    "}\n",
    "\n",
    "# Dictionary of parameters\n",
    "dict_parameters = {\n",
    "    #\"effect_sizes\": effect_sizes,\n",
    "    \"n_days\": n_days,\n",
    "    \"priors\": priors.keys()\n",
    "}\n",
    "\n",
    "trials = 50\n",
    "chains = 4\n",
    "cores = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _xla_gc_callback at 0x0000027A0606B880>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\PC\\Documents\\WorkLocal\\DataScience\\GitHub\\BayesianModelingExperiments\\venv\\Lib\\site-packages\\jax\\_src\\lib\\__init__.py\", line 96, in _xla_gc_callback\n",
      "    def _xla_gc_callback(*args):\n",
      "    \n",
      "KeyboardInterrupt: \n",
      "Sampling: [conversion_rate_control, conversion_rate_experiment, outcome_control, outcome_experiment]\n",
      "Sampling: [conversion_rate_control, conversion_rate_experiment, outcome_control, outcome_experiment]\n",
      "Sampling: [conversion_rate_control, conversion_rate_experiment, outcome_control, outcome_experiment]\n"
     ]
    }
   ],
   "source": [
    "# Calculate \"loss reduction\" for each parameter combination\n",
    "#effects_list = []\n",
    "days_list = []\n",
    "priors_list = []\n",
    "losses_list = []\n",
    "posterior_list = []\n",
    "for j, config in tqdm(\n",
    "    enumerate(grid_configs(dict_parameters)),\n",
    "    desc = \"configs\",\n",
    "    total = len(priors) * len(n_days)\n",
    "    ):\n",
    "\n",
    "    # Get parameters\n",
    "    ##effect_size = config[\"effect_sizes\"]\n",
    "    days = config[\"n_days\"]\n",
    "    prior_label = config[\"priors\"]\n",
    "\n",
    "    # Calculate experiment conversion rate relative to control, based on effect size\n",
    "    #exp_conv = (effect_size + 1) * conversion_control\n",
    "\n",
    "    loss_trials = []\n",
    "    posterior_trials = []\n",
    "    for i in tqdm(\n",
    "        range(trials),\n",
    "        desc = \"trials\",\n",
    "        total = trials\n",
    "        ):\n",
    "\n",
    "        # Create model\n",
    "        model = ConversionRateModel(\n",
    "            priors = priors[prior_label],\n",
    "            data = generate_variant_data(\n",
    "                days = days, \n",
    "                conversion_rates = [conversion_control, conversion_experiment]\n",
    "            ),\n",
    "            priors_label = prior_label\n",
    "        )\n",
    "\n",
    "        # Get prior predictive, mean estimated effect size\n",
    "        model.get_prior_predictive()\n",
    "        mu_prior = model.prior_predictive.prior.relative_uplift.mean()\n",
    "\n",
    "        # Get posterior predictive, mean estimated effect size\n",
    "        model.get_posterior_predictive(nuts_sampler = \"blackjax\", chains = chains, cores = cores, progressbar = False)\n",
    "        mu_posterior = model.posterior_predictive.posterior.relative_uplift.mean()\n",
    "\n",
    "        # Calculate & record loss reduction\n",
    "        # Loss from prior estimate - loss from posterior estimate\n",
    "        loss_reduction = np.abs(true_relative_uplift - mu_prior) - np.abs(true_relative_uplift - mu_posterior)\n",
    "        loss_trials.append(loss_reduction)\n",
    "\n",
    "        # Save posterior predictive sample for trial\n",
    "        posterior_trials.append(\n",
    "            np.ravel(model.posterior_predictive.posterior.relative_uplift)\n",
    "        )\n",
    "    \n",
    "    # Save parameters, trial average loss, list of posterior predictive samples for each config\n",
    "    #effects_list.append(true_relative_uplift)\n",
    "    days_list.append(days)\n",
    "    priors_list.append(prior_label)\n",
    "    losses_list.append(np.mean(loss_trials))\n",
    "    posterior_list.append(posterior_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 effect size, 9 parameter configs (3 sample sizes, 3 priors), 100 trials per config: ~19 min per config MINIMUM, ~3hrs with default sampler MINIMUM\n",
    "\n",
    "1 effect size, 15 parameter configs (5 sample sizes, 3 priors), 50 trials per config: ~3-10 min per config, ~45-150mins with blackjax sampler\n",
    "\n",
    "GPU sampler with JAX is also available, but only on Linux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactor EVSI as loss reduction with sample size: \n",
    "\n",
    "EVSI = loss(prior_estimate) - loss(posterior_estimate) \n",
    "= abs(actual_effect - prior_effect) - abs(actual effect - posterior effect)\n",
    "\n",
    "If the prior estimate is better, it will have lower loss than the posterior -> negative EVSI\n",
    "\n",
    "If the posterior estimate is better, it will have lower loss than the prior -> positive EVSI\n",
    "\n",
    "If prior-posterior estimates are identical, their loss will be identical -> zero EVSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample size vs. loss plot\n",
    "_ = sns.lineplot(\n",
    "    x = days_list,\n",
    "    y = losses_list,\n",
    "    hue = priors_list,\n",
    "    style = priors_list,\n",
    "    markers = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predictive distributions plot, for each sample size\n",
    "unique_days = set(days_list)\n",
    "\n",
    "fig, ax = plt.subplots(len(unique_days), sharex = True)\n",
    "fig.suptitle(\"Posterior predictive distributions by n. of days in simulation\")\n",
    "fig.supxlabel(f\"Relative uplift, true value: {round(true_relative_uplift, 2)}\")\n",
    "fig.legend(\n",
    "    handles = [\n",
    "        mpatches.Patch(color = \"blue\", label = \"Weak prior\"),\n",
    "        mpatches.Patch(color = \"orange\", label = \"Medium prior\"),\n",
    "        mpatches.Patch(color = \"green\", label = \"Strong prior\")\n",
    "    ],\n",
    "    loc = \"right\"\n",
    ")\n",
    "\n",
    "for n_days in unique_days:\n",
    "\n",
    "    ax_idx = list(unique_days).index(n_days)\n",
    "\n",
    "    trials_array = np.reshape(\n",
    "        np.array(posterior_list)[np.array(days_list) == n_days],\n",
    "        (len(priors) * trials, 4000)\n",
    "    )\n",
    "\n",
    "    colors = [\"blue\"] * trials + [\"orange\"] * trials + [\"green\"] * trials\n",
    "\n",
    "    for i in range(0, trials_array.shape[0]):\n",
    "        sns.kdeplot(\n",
    "            trials_array[i, :],\n",
    "            color = colors[i],\n",
    "            ax = ax[ax_idx],\n",
    "        )\n",
    "    \n",
    "    ax[ax_idx].set_ylabel(f\"{n_days} days\")\n",
    "    ax[ax_idx].axvline(true_relative_uplift, color = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "strong_prior_model = ConversionRateModel(\n",
    "    priors = strong_prior,\n",
    "    data = generate_variant_data(\n",
    "        days = 1, \n",
    "        conversion_rates = [conversion_control, conversion_experiment]\n",
    "    ),\n",
    "    priors_label = \"strong\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior predictive check\n",
    "strong_prior_model.plot_prior_predictive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_prior_model.plot_posterior_predictive()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
